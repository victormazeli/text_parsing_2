{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9h/54dfvmjx06g4n4wz3s4r5svw0000gn/T/ipykernel_1052/1603855159.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Importing Libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import threading \n",
    "import cv2\n",
    "from pygame import mixer \n",
    "from math import pow, sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = './SSD_MobileNet.caffemodel'\n",
    "path_prototxt = './SSD_MobileNet_prototxt.txt'\n",
    "path_label = './class_labels.txt'\n",
    "cap = cv2.VideoCapture(0)\n",
    "################################################################################################################################\n",
    "confidence_req = 0.8      ##### Minimum confidence for human detection #####\n",
    "h_source = 11             #####      Acutal length of reference        #####\n",
    "h_target = 28             #####      Acutal length of Target           #####\n",
    "F = 800                   #####      Focal length of camera            #####\n",
    "################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Labels for network\n",
    "labels = [line.strip() for line in open(path_label)]\n",
    "#print(labels)\n",
    "bounding_box_color = np.random.uniform(0, 255, size=(len(labels), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Netowork\n",
    "network = cv2.dnn.readNetFromCaffe(path_prototxt, path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alert():\n",
    "    # Starting the mixer \n",
    "    mixer.init() \n",
    "\n",
    "    # Loading the song \n",
    "    mixer.music.load('./Alarm.mp3') \n",
    "\n",
    "    # Setting the volume \n",
    "    mixer.music.set_volume(0.7) \n",
    "\n",
    "    # Start playing the song \n",
    "    mixer.music.play() \n",
    "    \n",
    "    # Sleep for 5 second\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #Pause the sound and close the mixer\n",
    "    mixer.music.pause()\n",
    "    mixer.music.stop()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(pri = True,dis = False):\n",
    "\n",
    "    frame_no = 0\n",
    "    first = True\n",
    "    source = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        \n",
    "        frame_no = frame_no+1\n",
    "\n",
    "        # Capture one frame after another\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        (h, w) = frame.shape[:2]\n",
    "\n",
    "        # Resize the frame to suite the model requirements. Resize the frame to 300X300 pixels\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 0.007843, (300, 300), 127.5)\n",
    "\n",
    "        network.setInput(blob)\n",
    "        detections = network.forward()\n",
    "\n",
    "        pos_dict = dict()\n",
    "        coordinates = dict()\n",
    "\n",
    "        for i in range(detections.shape[2]):\n",
    "\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "\n",
    "            if confidence > confidence_req:\n",
    "\n",
    "                class_id = int(detections[0, 0, i, 1])\n",
    "\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (startX, startY, endX, endY) = box.astype('int')\n",
    "\n",
    "                # Filtering only persons detected in the frame. Class Id of 'person' is 15\n",
    "                if class_id == 15.00:\n",
    "                    \n",
    "                    if dis:\n",
    "                        # Draw bounding box for the object\n",
    "                        cv2.rectangle(frame, (startX, startY), (endX, endY), bounding_box_color[class_id], 2)\n",
    "                    \n",
    "                    label = \"{}: {:.2f}%\".format(labels[class_id], confidence * 100)\n",
    "                    if pri:\n",
    "                        print(\"{}\".format(label))\n",
    "\n",
    "\n",
    "                    coordinates[i] = (startX, startY, endX, endY)\n",
    "\n",
    "                    # Mid point of bounding box\n",
    "                    x_mid = round((startX+endX)/2,4)\n",
    "                    y_mid = round((startY+endY)/2,4)\n",
    "\n",
    "                    height = round(endY-startY,4)\n",
    "                    # Distance from camera based on triangle similarity\n",
    "                    \n",
    "                    # For Source\n",
    "                    if first:\n",
    "                        distance = (h_source * F)/height\n",
    "                        first = False\n",
    "                        if pri:\n",
    "                            print(\"Distance from camera(cm):{dist}\\n\".format(dist=distance))\n",
    "\n",
    "                        # Mid-point of bounding boxes (in cm) based on triangle similarity technique\n",
    "                        x_mid_cm = (x_mid * distance) / F\n",
    "                        y_mid_cm = (y_mid * distance) / F\n",
    "                        source = (x_mid_cm,y_mid_cm,distance)\n",
    "                        \n",
    "                    # For Targets\n",
    "                    else:\n",
    "                        distance = (h_target * F)/height\n",
    "                        if pri:\n",
    "                            print(\"Distance from camera(cm):{dist}\\n\".format(dist=distance))\n",
    "\n",
    "                        # Mid-point of bounding boxes (in cm) based on triangle similarity technique\n",
    "                        x_mid_cm = (x_mid * distance) / F\n",
    "                        y_mid_cm = (y_mid * distance) / F\n",
    "                        pos_dict[i] = (x_mid_cm,y_mid_cm,distance)\n",
    "\n",
    "        # Distance between Source and every Target detected in a frame\n",
    "        close_objects = set()\n",
    "        for i in pos_dict.keys():\n",
    "            \n",
    "            dist = sqrt(pow(abs(pos_dict[i][0]-source[0]),2) + pow(abs(pos_dict[i][1]-source[1]),2) + pow(abs(pos_dict[i][2]-source[2]),2))\n",
    "            \n",
    "            COLOR = (0,255,0)\n",
    "            if pri:\n",
    "                print(dist)\n",
    "            if dist <= 20:\n",
    "                close_objects.add(i)\n",
    "                COLOR = (0,0,255)\n",
    "            if dis:\n",
    "                cv2.putText(frame, 'Distance from source: {i} cm'.format(i=round(dist,4)), (startX, startY+200),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLOR, 2)\n",
    "                \n",
    "        # Check if any Target is too close to the Source\n",
    "        if len(close_objects) > 1:\n",
    "            alert()\n",
    "        if dis:\n",
    "            for i in pos_dict.keys():\n",
    "\n",
    "                if i in close_objects:\n",
    "                    COLOR = (0,0,255)\n",
    "                else:\n",
    "                    COLOR = (0,255,0)\n",
    "                (startX, startY, endX, endY) = coordinates[i]\n",
    "\n",
    "                cv2.rectangle(frame, (startX, startY), (endX, endY), COLOR, 2)\n",
    "                y = startY - 15 if startY - 15 > 15 else startY + 15\n",
    "                # Convert cms to feet\n",
    "                cv2.putText(frame, 'Distance from camera: {i} cm'.format(i=round(pos_dict[i][2],4)), (startX, y),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLOR, 2)\n",
    "\n",
    "            cv2.namedWindow('Frame',cv2.WINDOW_NORMAL)\n",
    "\n",
    "            # Show frame\n",
    "            cv2.imshow('Frame', frame)\n",
    "            cv2.resizeWindow('Frame',800,600)\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "            # Press `q` to exit\n",
    "            if key == ord(\"q\"):\n",
    "                break\n",
    "    if dis:\n",
    "        # Clean\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 15 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_53054/3659155739.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# dis - Display Information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_53054/1432927815.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(pri, dis)\u001b[0m\n\u001b[1;32m     44\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mdis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                         \u001b[0;31m# Draw bounding box for the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstartX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstartY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mendX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounding_box_color\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{}: {:.2f}%\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidence\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 15 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "# pri - Print Information\n",
    "# dis - Display Information\n",
    "\n",
    "detect(pri = True,dis = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
